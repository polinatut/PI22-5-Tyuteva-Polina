{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задачи для совместного разбора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['basis', '.', 'panel', 'functionality', 'librarian', 'library', 'providing', 'the', 'a', 'convenient', 'infrastructure', 'Pandas', 'DataFrame', 'main', 'processing', 'for', 'is', 'NumPy', ',', 'built', 'class', 'The', 'of', 'data', 'on']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "text = 'Pandas is a librarian built on the basis of the functionality of the NumPy library, providing a convenient infrastructure for processing panel data. The main class of Pandas is DataFrame.'\n",
    "words = list(set(nltk.word_tokenize(text)))\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пара: ['a', 'panel'], расстояние редактирования: 4\n",
      "Пара: ['providing', 'librarian'], расстояние редактирования: 8\n",
      "Пара: [',', 'library'], расстояние редактирования: 7\n",
      "Пара: ['is', 'a'], расстояние редактирования: 2\n",
      "Пара: ['basis', 'library'], расстояние редактирования: 6\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from nltk.metrics import *\n",
    "lst = [0] * 5\n",
    "for i in range(5):\n",
    "    lst[i] = random.sample(words, 2)\n",
    "    print(f'Пара: {lst[i]}, расстояние редактирования: {edit_distance(lst[i][0], lst[i][1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class', 'basis', 'a', 'main', 'is']\n"
     ]
    }
   ],
   "source": [
    "def find_words(word, k):\n",
    "    dct = {w: edit_distance(w, word) for w in words}\n",
    "    dct = sorted(dct, key = dct.get)[:k]\n",
    "    return dct\n",
    "print(find_words('class', 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\tyute\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>normalized_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>basis</th>\n",
       "      <td>basi</td>\n",
       "      <td>basis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>panel</th>\n",
       "      <td>panel</td>\n",
       "      <td>panel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>functionality</th>\n",
       "      <td>function</td>\n",
       "      <td>functionality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>librarian</th>\n",
       "      <td>librarian</td>\n",
       "      <td>librarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>library</th>\n",
       "      <td>librari</td>\n",
       "      <td>library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>providing</th>\n",
       "      <td>provid</td>\n",
       "      <td>providing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convenient</th>\n",
       "      <td>conveni</td>\n",
       "      <td>convenient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure</th>\n",
       "      <td>infrastructur</td>\n",
       "      <td>infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pandas</th>\n",
       "      <td>panda</td>\n",
       "      <td>Pandas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DataFrame</th>\n",
       "      <td>datafram</td>\n",
       "      <td>DataFrame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main</th>\n",
       "      <td>main</td>\n",
       "      <td>main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processing</th>\n",
       "      <td>process</td>\n",
       "      <td>processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumPy</th>\n",
       "      <td>numpi</td>\n",
       "      <td>NumPy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>built</th>\n",
       "      <td>built</td>\n",
       "      <td>built</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>class</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The</th>\n",
       "      <td>the</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>data</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 stemmed_word normalized_word\n",
       "basis                    basi           basis\n",
       ".                           .               .\n",
       "panel                   panel           panel\n",
       "functionality        function   functionality\n",
       "librarian           librarian       librarian\n",
       "library               librari         library\n",
       "providing              provid       providing\n",
       "the                       the             the\n",
       "a                           a               a\n",
       "convenient            conveni      convenient\n",
       "infrastructure  infrastructur  infrastructure\n",
       "Pandas                  panda          Pandas\n",
       "DataFrame            datafram       DataFrame\n",
       "main                     main            main\n",
       "processing            process      processing\n",
       "for                       for             for\n",
       "is                         is              is\n",
       "NumPy                   numpi           NumPy\n",
       ",                           ,               ,\n",
       "built                   built           built\n",
       "class                   class           class\n",
       "The                       the             The\n",
       "of                         of              of\n",
       "data                     data            data\n",
       "on                         on              on"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import SnowballStemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "df = pd.DataFrame({'stemmed_word': [stemmer.stem(word) for word in words], 'normalized_word': [lemmatizer.lemmatize(word) for word in words]}, index=words)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tyute\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля стоп-слов в тексте: 18.44%\n",
      "Топ-10 слов до удаления стоп-слов: ['the', 'of', 'pandas', 'is', 'a', '.', 'librarian', 'built', 'on', 'basis']\n",
      "Топ-10 после удаления стоп-слов: ['pandas', '.', 'librarian', 'built', 'basis', 'functionality', 'numpy', 'library', ',', 'providing']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "text = 'Pandas is a librarian built on the basis of the functionality of the NumPy library, providing a convenient infrastructure for processing panel data. The main class of Pandas is DataFrame.'\n",
    "\n",
    "tokens = word_tokenize(text.lower())\n",
    "english_stopwords = stopwords.words('english')\n",
    "tokens_without_stopwords = [word for word in tokens if word not in english_stopwords]\n",
    "\n",
    "print(f\"Доля стоп-слов в тексте: {len(tokens) / len(english_stopwords):.2%}\")\n",
    "print(f\"Топ-10 слов до удаления стоп-слов: {[word for word, count in Counter(tokens).most_common(10)]}\")\n",
    "print(f\"Топ-10 после удаления стоп-слов: {[word for word, count in Counter(tokens_without_stopwords).most_common(10)]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Рецепт 1: [[0.         0.         0.         0.         0.         0.09912595\n",
      "  0.06921947 0.         0.         0.32913396 0.         0.\n",
      "  0.         0.09912595 0.         0.09912595 0.12286406 0.\n",
      "  0.         0.12286406 0.         0.         0.12286406 0.12286406\n",
      "  0.         0.         0.         0.19825189 0.         0.\n",
      "  0.12286406 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.12286406 0.         0.         0.08228349\n",
      "  0.         0.         0.08228349 0.         0.         0.\n",
      "  0.12286406 0.         0.12286406 0.09912595 0.09912595 0.\n",
      "  0.09912595 0.16456698 0.12286406 0.12286406 0.         0.\n",
      "  0.12286406 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.12286406 0.         0.\n",
      "  0.         0.         0.12286406 0.         0.         0.\n",
      "  0.         0.12286406 0.         0.         0.         0.\n",
      "  0.12286406 0.         0.         0.         0.         0.12286406\n",
      "  0.12286406 0.         0.         0.12286406 0.19825189 0.\n",
      "  0.         0.         0.12286406 0.24572811 0.         0.\n",
      "  0.         0.         0.         0.         0.12286406 0.12286406\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.19825189 0.12286406 0.         0.         0.         0.\n",
      "  0.         0.24685047 0.         0.         0.         0.\n",
      "  0.         0.         0.08228349 0.         0.29737784 0.\n",
      "  0.         0.12286406 0.         0.         0.         0.12286406\n",
      "  0.         0.         0.         0.         0.12286406 0.\n",
      "  0.24572811 0.         0.12286406 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]]\n",
      "Рецепт 2: [[0.         0.         0.         0.         0.14601054 0.\n",
      "  0.16451958 0.11780038 0.14601054 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14601054 0.         0.         0.\n",
      "  0.         0.14601054 0.         0.         0.14601054 0.\n",
      "  0.         0.         0.14601054 0.         0.         0.\n",
      "  0.         0.14601054 0.         0.29335488 0.14601054 0.\n",
      "  0.14601054 0.14601054 0.         0.         0.         0.09778496\n",
      "  0.14601054 0.         0.         0.         0.         0.\n",
      "  0.         0.14601054 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14601054 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.14601054\n",
      "  0.         0.23560077 0.         0.14601054 0.14601054 0.14601054\n",
      "  0.14601054 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14601054 0.         0.\n",
      "  0.         0.14601054 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.14601054 0.         0.14601054\n",
      "  0.14601054 0.         0.         0.14601054 0.43803162 0.\n",
      "  0.         0.         0.09778496 0.         0.         0.09778496\n",
      "  0.         0.         0.         0.14601054 0.14601054 0.\n",
      "  0.         0.         0.14601054 0.         0.         0.\n",
      "  0.         0.         0.         0.14601054 0.         0.\n",
      "  0.         0.         0.         0.         0.        ]]\n",
      "Рецепт 3: [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.39079369 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.39079369 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.26171909 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.39079369 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.31528989 0.         0.         0.         0.39079369 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.26171909 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.39079369 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]]\n",
      "Рецепт 4: [[0.         0.         0.         0.         0.         0.16568466\n",
      "  0.11569729 0.16568466 0.         0.13753323 0.         0.\n",
      "  0.         0.16568466 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.20536186 0.         0.         0.         0.         0.20536186\n",
      "  0.         0.         0.         0.         0.20536186 0.\n",
      "  0.         0.         0.         0.13753323 0.         0.\n",
      "  0.         0.         0.         0.20536186 0.         0.\n",
      "  0.         0.         0.13753323 0.         0.         0.20536186\n",
      "  0.         0.         0.         0.         0.16568466 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20536186 0.         0.         0.20536186 0.20536186\n",
      "  0.41072372 0.         0.         0.         0.20536186 0.\n",
      "  0.         0.16568466 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.20536186 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.13753323 0.         0.         0.         0.\n",
      "  0.         0.13753323 0.13753323 0.         0.         0.13753323\n",
      "  0.20536186 0.         0.         0.         0.         0.\n",
      "  0.20536186 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.20536186 0.         0.        ]]\n",
      "Рецепт 5: [[0.08946173 0.08946173 0.08946173 0.08946173 0.         0.\n",
      "  0.05040118 0.         0.         0.05991357 0.08946173 0.08946173\n",
      "  0.08946173 0.         0.08946173 0.07217716 0.         0.08946173\n",
      "  0.08946173 0.         0.         0.08946173 0.         0.\n",
      "  0.         0.         0.17892347 0.07217716 0.         0.\n",
      "  0.         0.08946173 0.         0.         0.         0.08946173\n",
      "  0.08946173 0.         0.17892347 0.11982713 0.         0.08946173\n",
      "  0.         0.         0.         0.         0.         0.05991357\n",
      "  0.         0.08946173 0.05991357 0.08946173 0.08946173 0.\n",
      "  0.         0.         0.         0.07217716 0.         0.08946173\n",
      "  0.14435433 0.11982713 0.         0.         0.         0.08946173\n",
      "  0.         0.         0.08946173 0.08946173 0.         0.\n",
      "  0.         0.         0.2683852  0.         0.         0.\n",
      "  0.08946173 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.08946173 0.08946173 0.08946173 0.08946173\n",
      "  0.         0.08946173 0.08946173 0.         0.08946173 0.\n",
      "  0.         0.         0.08946173 0.         0.07217716 0.08946173\n",
      "  0.08946173 0.08946173 0.         0.         0.17892347 0.08946173\n",
      "  0.08946173 0.08946173 0.17892347 0.08946173 0.         0.\n",
      "  0.08946173 0.17892347 0.08946173 0.         0.08946173 0.08946173\n",
      "  0.         0.         0.08946173 0.         0.         0.\n",
      "  0.         0.23965426 0.08946173 0.         0.         0.08946173\n",
      "  0.08946173 0.05991357 0.         0.08946173 0.07217716 0.29956783\n",
      "  0.         0.         0.08946173 0.         0.         0.\n",
      "  0.         0.08946173 0.         0.08946173 0.         0.08946173\n",
      "  0.         0.         0.         0.         0.08946173 0.08946173\n",
      "  0.17892347 0.08946173 0.         0.17892347 0.17892347]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "recipes = pd.read_csv('recipes_sample.csv', delimiter=',')\n",
    "recipes = recipes.head()\n",
    "vectors = vectorizer.fit_transform(recipes['description'])\n",
    "\n",
    "for i in range(vectors.shape[0]):\n",
    "    print(f\"Рецепт {i+1}: {vectors[i].toarray()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9725198666999536\n",
      "0.8944228631111404\n",
      "0.8408701219963103\n",
      "0.8093525908759086\n",
      "1.0\n",
      "0.8551689750098787\n",
      "0.9214042717289879\n",
      "0.9640049285228507\n",
      "0.9529584291886545\n",
      "0.8788072331736545\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy\n",
    "import pandas as pd\n",
    "lst =[]\n",
    "for el in recipes['description']:\n",
    "    lst.append(word_tokenize(el))\n",
    "vectors  = vectorizer.fit_transform(recipes['description']).toarray()\n",
    "for index_1 in range(len(lst)):\n",
    "    for index_2 in range(index_1 + 1, len(lst)):\n",
    "        print(distance.cosine(vectors[index_1], vectors[index_2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
